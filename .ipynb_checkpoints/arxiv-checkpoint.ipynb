{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42461294-cfdc-49e0-9658-a86034620f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# резервный список категорий на случай если парсинг сайта не сработает\n",
    "TAXONOMY_R = {'math.AC': {'name': 'Commutative Algebra',\n",
    "  'description': 'Commutative rings, modules, ideals, homological algebra, computational aspects, invariant theory, connections to algebraic geometry and combinatorics'},\n",
    " 'math.AG': {'name': 'Algebraic Geometry',\n",
    "  'description': 'Algebraic varieties, stacks, sheaves, schemes, moduli spaces, complex geometry, quantum cohomology'},\n",
    " 'math.AP': {'name': 'Analysis of PDEs',\n",
    "  'description': \"Existence and uniqueness, boundary conditions, linear and non-linear operators, stability, soliton theory, integrable PDE's, conservation laws, qualitative dynamics\"},\n",
    " 'math.AT': {'name': 'Algebraic Topology',\n",
    "  'description': 'Homotopy theory, homological algebra, algebraic treatments of manifolds'},\n",
    " 'math.CA': {'name': 'Classical Analysis and ODEs',\n",
    "  'description': \"Special functions, orthogonal polynomials, harmonic analysis, ODE's, differential relations, calculus of variations, approximations, expansions, asymptotics\"},\n",
    " 'math.CO': {'name': 'Combinatorics',\n",
    "  'description': 'Discrete mathematics, graph theory, enumeration, combinatorial optimization, Ramsey theory, combinatorial game theory'},\n",
    " 'math.CT': {'name': 'Category Theory',\n",
    "  'description': 'Enriched categories, topoi, abelian categories, monoidal categories, homological algebra'},\n",
    " 'math.CV': {'name': 'Complex Variables',\n",
    "  'description': 'Holomorphic functions, automorphic group actions and forms, pseudoconvexity, complex geometry, analytic spaces, analytic sheaves'},\n",
    " 'math.DG': {'name': 'Differential Geometry',\n",
    "  'description': 'Complex, contact, Riemannian, pseudo-Riemannian and Finsler geometry, relativity, gauge theory, global analysis'},\n",
    " 'math.DS': {'name': 'Dynamical Systems',\n",
    "  'description': 'Dynamics of differential equations and flows, mechanics, classical few-body problems, iterations, complex dynamics, delayed differential equations'},\n",
    " 'math.FA': {'name': 'Functional Analysis',\n",
    "  'description': 'Banach spaces, function spaces, real functions, integral transforms, theory of distributions, measure theory'},\n",
    " 'math.GM': {'name': 'General Mathematics',\n",
    "  'description': 'Mathematical material of general interest, topics not covered elsewhere'},\n",
    " 'math.GN': {'name': 'General Topology',\n",
    "  'description': 'Continuum theory, point-set topology, spaces with algebraic structure, foundations, dimension theory, local and global properties'},\n",
    " 'math.GR': {'name': 'Group Theory',\n",
    "  'description': 'Finite groups, topological groups, representation theory, cohomology, classification and structure'},\n",
    " 'math.GT': {'name': 'Geometric Topology',\n",
    "  'description': 'Manifolds, orbifolds, polyhedra, cell complexes, foliations, geometric structures'},\n",
    " 'math.HO': {'name': 'History and Overview',\n",
    "  'description': 'Biographies, philosophy of mathematics, mathematics education, recreational mathematics, communication of mathematics, ethics in mathematics'},\n",
    " 'math.IT': {'name': 'Information Theory',\n",
    "  'description': 'math.IT is an alias for cs.IT. Covers theoretical and experimental aspects of information theory and coding.'},\n",
    " 'math.KT': {'name': 'K-Theory and Homology',\n",
    "  'description': 'Algebraic and topological K-theory, relations with topology, commutative algebra, and operator algebras'},\n",
    " 'math.LO': {'name': 'Logic',\n",
    "  'description': 'Logic, set theory, point-set topology, formal mathematics'},\n",
    " 'math.MG': {'name': 'Metric Geometry',\n",
    "  'description': 'Euclidean, hyperbolic, discrete, convex, coarse geometry, comparisons in Riemannian geometry, symmetric spaces'},\n",
    " 'math.MP': {'name': 'Mathematical Physics',\n",
    "  'description': 'math.MP is an alias for math-ph. Articles in this category focus on areas of research that illustrate the application of mathematics to problems in physics, develop mathematical methods for such applications, or provide mathematically rigorous formulations of existing physical theories. Submissions to math-ph should be of interest to both physically oriented mathematicians and mathematically oriented physicists; submissions which are primarily of interest to theoretical physicists or to mathematicians should probably be directed to the respective physics/math categories'},\n",
    " 'math.NA': {'name': 'Numerical Analysis',\n",
    "  'description': 'Numerical algorithms for problems in analysis and algebra, scientific computation'},\n",
    " 'math.NT': {'name': 'Number Theory',\n",
    "  'description': 'Prime numbers, diophantine equations, analytic number theory, algebraic number theory, arithmetic geometry, Galois theory'},\n",
    " 'math.OA': {'name': 'Operator Algebras',\n",
    "  'description': 'Algebras of operators on Hilbert space, C^*-algebras, von Neumann algebras, non-commutative geometry'},\n",
    " 'math.OC': {'name': 'Optimization and Control',\n",
    "  'description': 'Operations research, linear programming, control theory, systems theory, optimal control, game theory'},\n",
    " 'math.PR': {'name': 'Probability',\n",
    "  'description': 'Theory and applications of probability and stochastic processes: e.g. central limit theorems, large deviations, stochastic differential equations, models from statistical mechanics, queuing theory'},\n",
    " 'math.QA': {'name': 'Quantum Algebra',\n",
    "  'description': 'Quantum groups, skein theories, operadic and diagrammatic algebra, quantum field theory'},\n",
    " 'math.RA': {'name': 'Rings and Algebras',\n",
    "  'description': 'Non-commutative rings and algebras, non-associative algebras, universal algebra and lattice theory, linear algebra, semigroups'},\n",
    " 'math.RT': {'name': 'Representation Theory',\n",
    "  'description': 'Linear representations of algebras and groups, Lie theory, associative algebras, multilinear algebra'},\n",
    " 'math.SG': {'name': 'Symplectic Geometry',\n",
    "  'description': 'Hamiltonian systems, symplectic flows, classical integrable systems'},\n",
    " 'math.SP': {'name': 'Spectral Theory',\n",
    "  'description': 'Schrodinger operators, operators on manifolds, general differential operators, numerical studies, integral operators, discrete models, resonances, non-self-adjoint operators, random operators/matrices'},\n",
    " 'math.ST': {'name': 'Statistics Theory',\n",
    "  'description': 'Applied, computational and theoretical statistics: e.g. statistical inference, regression, time series, multivariate analysis, data analysis, Markov chain Monte Carlo, design of experiments, case studies'}\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49d7f4b6-023b-4ea1-a76a-3978eb0d84ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Fetching taxonomy...\n",
      "Taxonomy loaded: 32 disciplines.\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ==========================================\n",
    "# ЧАСТЬ 1: ПОЛУЧЕНИЕ ТАКСОНОМИИ (С ОПИСАНИЯМИ)\n",
    "# ==========================================\n",
    "\n",
    "def get_arxiv_taxonomy_with_descriptions(section_filter='math'):\n",
    "    url = \"https://arxiv.org/category_taxonomy\"\n",
    "    taxonomy = {}\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Находим заголовок Mathematics\n",
    "        math_header = soup.find('h2', string=re.compile(r'Mathematics', re.IGNORECASE))\n",
    "        \n",
    "        if math_header:\n",
    "            content_block = math_header.find_next_sibling('div', class_='accordion-body')\n",
    "            if content_block:\n",
    "                for h4 in content_block.find_all('h4'):\n",
    "                    # Парсим заголовок: math.AG (Algebraic Geometry)\n",
    "                    full_text = h4.get_text(separator=' ', strip=True)\n",
    "                    match = re.search(r'(math\\.[A-Z]{2,})\\s*\\((.+)\\)', full_text)\n",
    "                    \n",
    "                    if match:\n",
    "                        code = match.group(1).strip()\n",
    "                        name = match.group(2).strip()\n",
    "                        \n",
    "                        # Парсим описание из соседней колонки\n",
    "                        description = \"\"\n",
    "                        parent_col = h4.find_parent('div', class_='column')\n",
    "                        if parent_col:\n",
    "                            desc_col = parent_col.find_next_sibling('div', class_='column')\n",
    "                            if desc_col:\n",
    "                                p_tag = desc_col.find('p')\n",
    "                                if p_tag:\n",
    "                                    description = p_tag.get_text(strip=True)\n",
    "                        \n",
    "                        taxonomy[code] = {'name': name, 'description': description}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching taxonomy: {e}\")\n",
    "        \n",
    "    return taxonomy\n",
    "\n",
    "print(\"1. Fetching taxonomy...\")\n",
    "TAXONOMY = get_arxiv_taxonomy_with_descriptions('math')\n",
    "\n",
    "# Fallback (если сайт лежит)\n",
    "if not TAXONOMY or len(TAXONOMY) < 5:\n",
    "    print(\"Warning: Using fallback taxonomy.\")\n",
    "    TAXONOMY = TAXONOMY_R\n",
    "\n",
    "# Берем ВСЕ категории для анализа\n",
    "ALL_CATEGORIES = list(TAXONOMY.keys())\n",
    "print(f\"Taxonomy loaded: {len(ALL_CATEGORIES)} disciplines.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5c36f-10bf-47c0-9695-6b42734cf67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Scanning data (Depth: 300 articles per category)...\n",
      "   This determines link weights and finds the best articles.\n",
      "   Processed math.AC: found 300 articles.\n",
      "   Processed math.AG: found 300 articles.\n",
      "   Processed math.AP: found 300 articles.\n",
      "   Processed math.AT: found 300 articles.\n",
      "   Processed math.CA: found 300 articles.\n",
      "   Processed math.CO: found 300 articles.\n",
      "   Processed math.CT: found 300 articles.\n",
      "   Processed math.CV: found 300 articles.\n",
      "   Processed math.DG: found 300 articles.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ЧАСТЬ 2: СБОР БОЛЬШИХ ДАННЫХ (SCAN)\n",
    "# ==========================================\n",
    "\n",
    "# Настройки\n",
    "ANALYSIS_DEPTH = 300       # Сколько статей скачивать для расчета ВЕСОВ (для каждой темы)\n",
    "DISPLAY_LIMIT = 15         # Сколько статей отображать в графе (для каждой темы)\n",
    "\n",
    "# Хранилища\n",
    "global_pair_counter = Counter()  # Для подсчета весов связей между дисциплинами\n",
    "candidates_per_topic = {topic: [] for topic in ALL_CATEGORIES} # Кандидаты на отображение\n",
    "seen_articles = set() # Чтобы не дублировать подсчеты\n",
    "\n",
    "client = arxiv.Client()\n",
    "\n",
    "print(f\"2. Scanning data (Depth: {ANALYSIS_DEPTH} articles per category)...\")\n",
    "print(\"   This determines link weights and finds the best articles.\")\n",
    "\n",
    "for topic in ALL_CATEGORIES:\n",
    "    # Запрашиваем много статей для статистики\n",
    "    search = arxiv.Search(\n",
    "        query = f\"cat:{topic}\",\n",
    "        max_results = ANALYSIS_DEPTH,\n",
    "        sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    \n",
    "    results = list(client.results(search))\n",
    "    \n",
    "    for r in results:\n",
    "        article_id = r.entry_id.split('/')[-1]\n",
    "        \n",
    "        # Очищаем категории (оставляем только те, что есть в нашей таксономии)\n",
    "        # Это важно, чтобы не связывать с физикой, если мы строим мат. граф\n",
    "        relevant_cats = sorted([c for c in r.categories if c in TAXONOMY])\n",
    "        \n",
    "        # 1. Считаем статистику для ВЕСОВ СВЯЗЕЙ (Global Weights)\n",
    "        # Считаем каждую пару только один раз для каждой статьи\n",
    "        if article_id not in seen_articles:\n",
    "            if len(relevant_cats) > 1:\n",
    "                for pair in combinations(relevant_cats, 2):\n",
    "                    global_pair_counter[pair] += 1\n",
    "            seen_articles.add(article_id)\n",
    "        \n",
    "        # 2. Собираем данные для КАНДИДАТОВ\n",
    "        # Рейтинг статьи = (Кол-во категорий * 10). \n",
    "        # Чем больше связей, тем интереснее статья для графа.\n",
    "        score = len(relevant_cats) * 10\n",
    "        \n",
    "        article_data = {\n",
    "            'id': article_id,\n",
    "            'title': r.title.replace('\\n', ' '),\n",
    "            'abstract': r.summary.replace('\\n', ' '),\n",
    "            'authors': [a.name for a in r.authors],\n",
    "            'date': r.published.strftime(\"%Y-%m-%d\"),\n",
    "            'primary_category': r.primary_category,\n",
    "            'categories': relevant_cats,\n",
    "            'url': r.entry_id,\n",
    "            'score': score # Для сортировки\n",
    "        }\n",
    "        \n",
    "        candidates_per_topic[topic].append(article_data)\n",
    "        \n",
    "    print(f\"   Processed {topic}: found {len(results)} articles.\")\n",
    "    time.sleep(0.2) # Не бомбим API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ea498-e346-4c8b-a709-4177f0f3a9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ЧАСТЬ 3: РАНЖИРОВАНИЕ И ОТБОР (TOP-15)\n",
    "# ==========================================\n",
    "\n",
    "print(f\"3. Ranking and selecting Top-{DISPLAY_LIMIT} articles per category...\")\n",
    "\n",
    "final_nodes_dict = {} # Словарь id -> node, чтобы избежать дублей узлов\n",
    "links = []\n",
    "\n",
    "# --- 3.1 Создаем узлы ДИСЦИПЛИН (Все 32) ---\n",
    "for code, info in TAXONOMY.items():\n",
    "    if isinstance(info, str): # Обработка fallback старого типа\n",
    "        name, desc = info, code\n",
    "    else:\n",
    "        name = info.get('name', code)\n",
    "        desc = info.get('description', \"\")\n",
    "        \n",
    "    final_nodes_dict[code] = {\n",
    "        \"id\": code,\n",
    "        \"label\": name,\n",
    "        \"type\": \"discipline\",\n",
    "        \"description\": desc,\n",
    "        \"cluster\": code,\n",
    "        \"val\": 30 # Дисциплины делаем большими\n",
    "    }\n",
    "\n",
    "# --- 3.2 Отбираем лучшие СТАТЬИ ---\n",
    "for topic in ALL_CATEGORIES:\n",
    "    candidates = candidates_per_topic[topic]\n",
    "    \n",
    "    # Сортировка: Сначала по score (интердисциплинарность), потом по дате (свежесть)\n",
    "    # Т.е. наверху будут свежие статьи, связывающие несколько областей\n",
    "    candidates.sort(key=lambda x: (x['score'], x['date']), reverse=True)\n",
    "    \n",
    "    # Берем топ-15\n",
    "    top_selection = candidates[:DISPLAY_LIMIT]\n",
    "    \n",
    "    for art in top_selection:\n",
    "        # Добавляем узел статьи, если его еще нет\n",
    "        if art['id'] not in final_nodes_dict:\n",
    "            \n",
    "            # Определяем кластер для раскраски\n",
    "            main_cluster = art['primary_category']\n",
    "            if main_cluster not in TAXONOMY:\n",
    "                # Если первичная не мат., берем первую попавшуюся мат. категорию\n",
    "                main_cluster = art['categories'][0] if art['categories'] else topic\n",
    "\n",
    "            final_nodes_dict[art['id']] = {\n",
    "                \"id\": art['id'],\n",
    "                \"label\": art['title'],\n",
    "                \"type\": \"article\",\n",
    "                \"description\": art['abstract'],\n",
    "                \"authors\": art['authors'],\n",
    "                \"cluster\": main_cluster,\n",
    "                \"val\": 5,\n",
    "                \"url\": art['url']\n",
    "            }\n",
    "            \n",
    "        # Добавляем связь CONTAINS (Дисциплина -> Статья)\n",
    "        # Важно: связываем только с ТЕКУЩЕЙ дисциплиной в цикле, \n",
    "        # чтобы структура была логичной (или со всеми ее категориями?)\n",
    "        # Лучше связать со всеми её категориями, которые есть в графе:\n",
    "        for cat in art['categories']:\n",
    "             links.append({\n",
    "                \"source\": cat,\n",
    "                \"target\": art['id'],\n",
    "                \"type\": \"CONTAINS\",\n",
    "                \"val\": 1\n",
    "            })\n",
    "\n",
    "# --- 3.3 Создаем связи ДИСЦИПЛИНА-ДИСЦИПЛИНА (на основе GLOBAL weights) ---\n",
    "if global_pair_counter:\n",
    "    max_weight = max(global_pair_counter.values())\n",
    "    print(f\"   Max co-occurrence strength: {max_weight}\")\n",
    "\n",
    "    for pair, count in global_pair_counter.items():\n",
    "        # Добавляем связь только если вес значимый (например > 2 совпадений в большой выборке)\n",
    "        if count >= 3: \n",
    "            links.append({\n",
    "                \"source\": pair[0],\n",
    "                \"target\": pair[1],\n",
    "                \"type\": \"RELATED\",\n",
    "                \"label\": f\"{count} shared articles (annual)\",\n",
    "                # Нормируем толщину от 1 до 10\n",
    "                \"val\": (count / max_weight) * 10\n",
    "            })\n",
    "\n",
    "# Чистим дубликаты связей (так как цикл по статьям мог добавить CONTAINS дважды)\n",
    "# Превращаем список словарей в множеств кортежей JSON строк для уникальности, потом обратно\n",
    "unique_links_set = set()\n",
    "final_links = []\n",
    "for l in links:\n",
    "    # Генерируем уникальный ключ для связи\n",
    "    link_id = f\"{l['source']}-{l['target']}-{l['type']}\"\n",
    "    if link_id not in unique_links_set:\n",
    "        final_links.append(l)\n",
    "        unique_links_set.add(link_id)\n",
    "\n",
    "nodes = list(final_nodes_dict.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a09e9-a71e-4f8c-a4cf-2f91aa690599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ЧАСТЬ 4: СОХРАНЕНИЕ\n",
    "# ==========================================\n",
    "\n",
    "OUTPUT_FILE = \"graph_data.json\"\n",
    "output_data = {\n",
    "    \"nodes\": nodes,\n",
    "    \"links\": final_links\n",
    "}\n",
    "\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"DONE! Data saved to {OUTPUT_FILE}\")\n",
    "print(f\"Nodes: {len(nodes)} (Should be approx {len(ALL_CATEGORIES) * DISPLAY_LIMIT} + 32)\")\n",
    "print(f\"Links: {len(final_links)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
